{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server\n",
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"]= \"/ceph/aboehret/cache/transformers\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"]= \"/ceph/aboehret/cache/datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as t\n",
    "from nnsight import LanguageModel\n",
    "import random\n",
    "import json\n",
    "\n",
    "# saprmarks/feature-circuits\n",
    "from feature_circuits.activation_utils import SparseAct\n",
    "from feature_circuits.attribution import patching_effect\n",
    "from feature_circuits.loading_utils import load_examples\n",
    "\n",
    "# saprmarks/dictionary-learning\n",
    "from feature_circuits.dictionary_learning import AutoEncoder\n",
    "\n",
    "# GPT\n",
    "from sae_lens.sae import SAE\n",
    "\n",
    "# Feature Selection\n",
    "from feature_selection import get_thres_features, get_topk_features, get_all_features\n",
    "\n",
    "# Neuronpedia\n",
    "import json\n",
    "import urllib.parse\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LLMs, SAEs, Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLM\n",
    "model_id = \"openai-community/gpt2\"\n",
    "gpt_model = LanguageModel(\n",
    "    model_id,\n",
    "    device_map = DEVICE,\n",
    "    dispatch = True,\n",
    ")\n",
    "D_GPT = gpt_model.config.hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ceph/aboehret/github/SAELens/sae_lens/sae.py:136: UserWarning: \n",
      "This SAE has non-empty model_from_pretrained_kwargs. \n",
      "For optimal performance, load the model like so:\n",
      "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load SAE\n",
    "\n",
    "# Submodules\n",
    "resids_gpt = [layer for layer in gpt_model.transformer.h]\n",
    "submodules_gpt = resids_gpt\n",
    "\n",
    "# Initialize dictionaries and submodule names\n",
    "dictionaries_gpt = {}\n",
    "submodule_names_gpt = {}\n",
    "\n",
    "# Loop through the layers (adjust the range according to the number of layers)\n",
    "for layer in range(12):  # Assuming 12 layers for GPT-2 small\n",
    "    \n",
    "    # Load the Sparse AutoEncoder (SAE) for the residual stream\n",
    "    sae, original_cfg_dict, sparsity = SAE.from_pretrained(\n",
    "        release=\"gpt2-small-res-jb\",\n",
    "        sae_id=f\"blocks.{layer}.hook_resid_pre\",  # For residual stream only\n",
    "        device=\"cuda:0\",\n",
    "    )\n",
    "\n",
    "    # Store the SAE in dictionaries for the residual layer\n",
    "    dictionaries_gpt[resids_gpt[layer]] = sae\n",
    "    submodule_names_gpt[resids_gpt[layer]] = f'resid_{layer}'\n",
    "\n",
    "D_GPT_SAE = original_cfg_dict['d_sae'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24576"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_GPT_SAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 50\n",
    "length = 3\n",
    "\n",
    "dataset  = './data/names.json'\n",
    "\n",
    "examples = load_examples(dataset, num_examples, gpt_model, length=length)\n",
    "\n",
    "m_inputs = t.cat([e['clean_prefix'] for e in examples], dim=0).to(DEVICE)\n",
    "f_inputs = t.cat([e['patch_prefix'] for e in examples], dim=0).to(DEVICE)\n",
    "m_answer_idxs = t.tensor([e['clean_answer'] for e in examples], dtype=t.long, device=DEVICE)\n",
    "f_answer_idxs = t.tensor([e['patch_answer'] for e in examples], dtype=t.long, device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Attribution patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metric - logit diff - GPT\n",
    "def metric_fn_gpt(model, clean_answer_idxs, patch_answer_idxs):\n",
    "    return (\n",
    "        t.gather(model.lm_head.output[:,-1,:], dim=-1, index=patch_answer_idxs.view(-1, 1)).squeeze(-1) - \\\n",
    "        t.gather(model.lm_head.output[:,-1,:], dim=-1, index=clean_answer_idxs.view(-1, 1)).squeeze(-1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "gpt_effects = patching_effect(\n",
    "        m_inputs,\n",
    "        f_inputs,\n",
    "        gpt_model,\n",
    "        submodules_gpt,\n",
    "        dictionaries_gpt,\n",
    "        metric_fn = metric_fn_gpt,\n",
    "        method = \"ig\",\n",
    "        metric_kwargs={'clean_answer_idxs': m_answer_idxs, 'patch_answer_idxs': f_answer_idxs},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.3620,  1.8214,  1.0027,  1.2407,  0.3196, -0.0615,  1.0351,  0.9023,\n",
      "         1.2059,  0.4982,  0.5997,  0.9434,  2.2439,  0.1985,  0.9752,  1.4090,\n",
      "         1.3567, -0.0089,  0.0506,  1.9677,  1.8285,  1.9017,  2.2235, -0.2364,\n",
      "         0.9286,  1.5553,  1.2649,  1.5764,  0.0510,  1.0388,  0.9724,  0.7769,\n",
      "         1.0179,  0.5372,  1.9119,  2.2669,  0.6777,  1.6479,  0.2966,  0.2693,\n",
      "         1.6358,  0.4645, -0.4090,  1.7394], device='cuda:0')\n",
      "Mean tensor(1.0227, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "_, _, _, total_g = gpt_effects\n",
    "print(total_g)\n",
    "print('Mean', total_g.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Analysis & Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes(clean_effects, clean_inputs, submodules):\n",
    "    nodes = None\n",
    "    running_total = 0\n",
    "    with t.no_grad():\n",
    "        if nodes is None:\n",
    "            nodes = {k : len(clean_inputs) * v.sum(dim=1).mean(dim=0) for k, v in clean_effects.items()}\n",
    "        else:\n",
    "            for k, v in clean_effects.items():\n",
    "                nodes[k] += len(clean_inputs) * v.sum(dim=1).mean(dim=0)\n",
    "        running_total += len(clean_inputs)\n",
    "\n",
    "    nodes = {k : v / running_total for k, v in nodes.items()}\n",
    "    \n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_nodes = get_nodes(gpt_effects.effects, m_inputs, submodules_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features with non-zero activation score: 263023\n"
     ]
    }
   ],
   "source": [
    "# All non-zero nodes\n",
    "all_gpt_features = get_all_features(gpt_nodes, submodule_names_gpt)\n",
    "print(f\"Total number of features with non-zero activation score: {sum(len(inner_dict) for inner_dict in all_gpt_features.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features with activation score above threshold: 48\n"
     ]
    }
   ],
   "source": [
    "# Threshold features\n",
    "gpt_thres = get_thres_features(gpt_nodes, threshold=0.1, submodule_names=submodule_names_gpt)\n",
    "print(f\"Total number of features with activation score above threshold: {sum(len(inner_dict) for inner_dict in gpt_thres.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'resid_0': {}, 'resid_1': {18756: 0.197266086935997, 5742: 0.17898690700531006, 16306: 0.17882031202316284}, 'resid_10': {11094: 0.3505690097808838, 23440: 0.27558112144470215, 20409: 0.20817120373249054, 5875: 0.17232660949230194, 13618: 0.15214762091636658}, 'resid_11': {4077: 0.4548037350177765, 13642: 0.26605644822120667, 5210: 0.2547995150089264, 8252: 0.15805856883525848, 24199: 0.141384094953537}, 'resid_2': {}, 'resid_3': {8216: 0.28700247406959534}, 'resid_4': {2911: 0.23512524366378784, 13416: 0.13550598919391632}, 'resid_5': {8578: 0.4652336835861206, 15506: 0.14001810550689697}, 'resid_6': {19260: 0.48122021555900574, 13066: 0.18763355910778046, 1545: 0.13741624355316162}, 'resid_7': {23247: 0.5228695869445801, 10619: 0.15829448401927948, 9058: 0.13447244465351105}, 'resid_8': {600: 0.42299896478652954, 15707: 0.23514270782470703, 1007: 0.16084255278110504}, 'resid_9': {7119: 0.3635866641998291, 14674: 0.2599882185459137, 20378: 0.1509484052658081}}\n",
      "Count: 30\n"
     ]
    }
   ],
   "source": [
    "top30_gpt = get_topk_features(gpt_nodes, top_n=30, submodule_names=submodule_names_gpt)\n",
    "print(top30_gpt)\n",
    "print(f\"Count: {sum(len(inner_dict) for inner_dict in top30_gpt.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Visualise features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dict_gpt(data_dict, model_id):\n",
    "    \n",
    "    layer_mapping = {\n",
    "            'resid_': 'res-jb',\n",
    "    }\n",
    "    result = []\n",
    "    \n",
    "    for component_idx, feature_indices in data_dict.items():\n",
    "        # Determine the type of layer based on the key\n",
    "        layer = component_idx\n",
    "        layer_prefix = ''.join([i for i in layer if not i.isdigit()])\n",
    "        layer_suffix = ''.join([i for i in layer if i.isdigit()])\n",
    "        layer_key = f\"{layer_mapping.get(layer_prefix, layer_prefix)}\"\n",
    "\n",
    "        # Add the information for each index in this layer\n",
    "        for index in feature_indices.keys():\n",
    "            result.append({\n",
    "                \"modelId\": model_id,\n",
    "                \"layer\": f\"{layer_suffix}-{layer_key}\",\n",
    "                \"index\": str(index)\n",
    "            })\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import webbrowser\n",
    "import json\n",
    "\n",
    "def get_neuronpedia_quicklist(features_list):\n",
    "    LIST_NAME = \"Gender features\"\n",
    "    LIST_FEATURES = features_list\n",
    "\n",
    "    url = \"https://neuronpedia.org/quick-list/\"\n",
    "    name = urllib.parse.quote(LIST_NAME)\n",
    "    url = url + \"?name=\" + name\n",
    "    url = url + \"&features=\" + urllib.parse.quote(json.dumps(LIST_FEATURES))\n",
    "\n",
    "    print(\"Opening: \" + url)\n",
    "    webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'modelId': 'gpt2-small', 'layer': '0-res-jb', 'index': '3161'}, {'modelId': 'gpt2-small', 'layer': '0-res-jb', 'index': '10037'}, {'modelId': 'gpt2-small', 'layer': '1-res-jb', 'index': '195'}, {'modelId': 'gpt2-small', 'layer': '1-res-jb', 'index': '5742'}, {'modelId': 'gpt2-small', 'layer': '1-res-jb', 'index': '7216'}, {'modelId': 'gpt2-small', 'layer': '1-res-jb', 'index': '16306'}, {'modelId': 'gpt2-small', 'layer': '1-res-jb', 'index': '18186'}, {'modelId': 'gpt2-small', 'layer': '1-res-jb', 'index': '18756'}, {'modelId': 'gpt2-small', 'layer': '1-res-jb', 'index': '23465'}, {'modelId': 'gpt2-small', 'layer': '2-res-jb', 'index': '5557'}, {'modelId': 'gpt2-small', 'layer': '3-res-jb', 'index': '8216'}, {'modelId': 'gpt2-small', 'layer': '4-res-jb', 'index': '1544'}, {'modelId': 'gpt2-small', 'layer': '4-res-jb', 'index': '2911'}, {'modelId': 'gpt2-small', 'layer': '4-res-jb', 'index': '13416'}, {'modelId': 'gpt2-small', 'layer': '5-res-jb', 'index': '8578'}, {'modelId': 'gpt2-small', 'layer': '5-res-jb', 'index': '10183'}, {'modelId': 'gpt2-small', 'layer': '5-res-jb', 'index': '13844'}, {'modelId': 'gpt2-small', 'layer': '5-res-jb', 'index': '15506'}, {'modelId': 'gpt2-small', 'layer': '6-res-jb', 'index': '1545'}, {'modelId': 'gpt2-small', 'layer': '6-res-jb', 'index': '4645'}, {'modelId': 'gpt2-small', 'layer': '6-res-jb', 'index': '13066'}, {'modelId': 'gpt2-small', 'layer': '6-res-jb', 'index': '19260'}, {'modelId': 'gpt2-small', 'layer': '7-res-jb', 'index': '9058'}, {'modelId': 'gpt2-small', 'layer': '7-res-jb', 'index': '10619'}, {'modelId': 'gpt2-small', 'layer': '7-res-jb', 'index': '19959'}, {'modelId': 'gpt2-small', 'layer': '7-res-jb', 'index': '23247'}, {'modelId': 'gpt2-small', 'layer': '8-res-jb', 'index': '600'}, {'modelId': 'gpt2-small', 'layer': '8-res-jb', 'index': '1007'}, {'modelId': 'gpt2-small', 'layer': '8-res-jb', 'index': '2896'}, {'modelId': 'gpt2-small', 'layer': '8-res-jb', 'index': '11952'}, {'modelId': 'gpt2-small', 'layer': '8-res-jb', 'index': '15707'}, {'modelId': 'gpt2-small', 'layer': '8-res-jb', 'index': '19874'}, {'modelId': 'gpt2-small', 'layer': '9-res-jb', 'index': '7119'}, {'modelId': 'gpt2-small', 'layer': '9-res-jb', 'index': '14674'}, {'modelId': 'gpt2-small', 'layer': '9-res-jb', 'index': '20378'}, {'modelId': 'gpt2-small', 'layer': '10-res-jb', 'index': '5875'}, {'modelId': 'gpt2-small', 'layer': '10-res-jb', 'index': '8585'}, {'modelId': 'gpt2-small', 'layer': '10-res-jb', 'index': '11094'}, {'modelId': 'gpt2-small', 'layer': '10-res-jb', 'index': '13618'}, {'modelId': 'gpt2-small', 'layer': '10-res-jb', 'index': '20409'}, {'modelId': 'gpt2-small', 'layer': '10-res-jb', 'index': '23440'}, {'modelId': 'gpt2-small', 'layer': '11-res-jb', 'index': '1613'}, {'modelId': 'gpt2-small', 'layer': '11-res-jb', 'index': '3884'}, {'modelId': 'gpt2-small', 'layer': '11-res-jb', 'index': '4077'}, {'modelId': 'gpt2-small', 'layer': '11-res-jb', 'index': '5210'}, {'modelId': 'gpt2-small', 'layer': '11-res-jb', 'index': '8252'}, {'modelId': 'gpt2-small', 'layer': '11-res-jb', 'index': '13642'}, {'modelId': 'gpt2-small', 'layer': '11-res-jb', 'index': '24199'}]\n",
      "Opening: https://neuronpedia.org/quick-list/?name=Gender%20features&features=%5B%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%220-res-jb%22%2C%20%22index%22%3A%20%223161%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%220-res-jb%22%2C%20%22index%22%3A%20%2210037%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%221-res-jb%22%2C%20%22index%22%3A%20%22195%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%221-res-jb%22%2C%20%22index%22%3A%20%225742%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%221-res-jb%22%2C%20%22index%22%3A%20%227216%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%221-res-jb%22%2C%20%22index%22%3A%20%2216306%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%221-res-jb%22%2C%20%22index%22%3A%20%2218186%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%221-res-jb%22%2C%20%22index%22%3A%20%2218756%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%221-res-jb%22%2C%20%22index%22%3A%20%2223465%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%222-res-jb%22%2C%20%22index%22%3A%20%225557%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%223-res-jb%22%2C%20%22index%22%3A%20%228216%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%224-res-jb%22%2C%20%22index%22%3A%20%221544%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%224-res-jb%22%2C%20%22index%22%3A%20%222911%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%224-res-jb%22%2C%20%22index%22%3A%20%2213416%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%225-res-jb%22%2C%20%22index%22%3A%20%228578%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%225-res-jb%22%2C%20%22index%22%3A%20%2210183%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%225-res-jb%22%2C%20%22index%22%3A%20%2213844%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%225-res-jb%22%2C%20%22index%22%3A%20%2215506%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%226-res-jb%22%2C%20%22index%22%3A%20%221545%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%226-res-jb%22%2C%20%22index%22%3A%20%224645%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%226-res-jb%22%2C%20%22index%22%3A%20%2213066%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%226-res-jb%22%2C%20%22index%22%3A%20%2219260%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%227-res-jb%22%2C%20%22index%22%3A%20%229058%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%227-res-jb%22%2C%20%22index%22%3A%20%2210619%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%227-res-jb%22%2C%20%22index%22%3A%20%2219959%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%227-res-jb%22%2C%20%22index%22%3A%20%2223247%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%22600%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%221007%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%222896%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2211952%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2215707%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2219874%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%229-res-jb%22%2C%20%22index%22%3A%20%227119%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%229-res-jb%22%2C%20%22index%22%3A%20%2214674%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%229-res-jb%22%2C%20%22index%22%3A%20%2220378%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2210-res-jb%22%2C%20%22index%22%3A%20%225875%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2210-res-jb%22%2C%20%22index%22%3A%20%228585%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2210-res-jb%22%2C%20%22index%22%3A%20%2211094%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2210-res-jb%22%2C%20%22index%22%3A%20%2213618%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2210-res-jb%22%2C%20%22index%22%3A%20%2220409%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2210-res-jb%22%2C%20%22index%22%3A%20%2223440%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2211-res-jb%22%2C%20%22index%22%3A%20%221613%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2211-res-jb%22%2C%20%22index%22%3A%20%223884%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2211-res-jb%22%2C%20%22index%22%3A%20%224077%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2211-res-jb%22%2C%20%22index%22%3A%20%225210%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2211-res-jb%22%2C%20%22index%22%3A%20%228252%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2211-res-jb%22%2C%20%22index%22%3A%20%2213642%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2211-res-jb%22%2C%20%22index%22%3A%20%2224199%22%7D%5D\n"
     ]
    }
   ],
   "source": [
    "gpt_features = transform_dict_gpt(gpt_thres, 'gpt2-small')\n",
    "print(gpt_features)\n",
    "get_neuronpedia_quicklist(gpt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: https://neuronpedia.org/quick-list/?name=Gender%20features&features=%5B%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%221-res-jb%22%2C%20%22index%22%3A%20%2218756%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%221-res-jb%22%2C%20%22index%22%3A%20%225742%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%221-res-jb%22%2C%20%22index%22%3A%20%2216306%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2210-res-jb%22%2C%20%22index%22%3A%20%2211094%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2210-res-jb%22%2C%20%22index%22%3A%20%2223440%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2210-res-jb%22%2C%20%22index%22%3A%20%2220409%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2210-res-jb%22%2C%20%22index%22%3A%20%225875%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2210-res-jb%22%2C%20%22index%22%3A%20%2213618%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2211-res-jb%22%2C%20%22index%22%3A%20%224077%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2211-res-jb%22%2C%20%22index%22%3A%20%2213642%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2211-res-jb%22%2C%20%22index%22%3A%20%225210%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2211-res-jb%22%2C%20%22index%22%3A%20%228252%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%2211-res-jb%22%2C%20%22index%22%3A%20%2224199%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%223-res-jb%22%2C%20%22index%22%3A%20%228216%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%224-res-jb%22%2C%20%22index%22%3A%20%222911%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%224-res-jb%22%2C%20%22index%22%3A%20%2213416%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%225-res-jb%22%2C%20%22index%22%3A%20%228578%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%225-res-jb%22%2C%20%22index%22%3A%20%2215506%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%226-res-jb%22%2C%20%22index%22%3A%20%2219260%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%226-res-jb%22%2C%20%22index%22%3A%20%2213066%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%226-res-jb%22%2C%20%22index%22%3A%20%221545%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%227-res-jb%22%2C%20%22index%22%3A%20%2223247%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%227-res-jb%22%2C%20%22index%22%3A%20%2210619%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%227-res-jb%22%2C%20%22index%22%3A%20%229058%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%22600%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2215707%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%221007%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%229-res-jb%22%2C%20%22index%22%3A%20%227119%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%229-res-jb%22%2C%20%22index%22%3A%20%2214674%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%229-res-jb%22%2C%20%22index%22%3A%20%2220378%22%7D%5D\n"
     ]
    }
   ],
   "source": [
    "top30_gpt_feat = transform_dict_gpt(top30_gpt, 'gpt2-small')\n",
    "get_neuronpedia_quicklist(top30_gpt_feat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
